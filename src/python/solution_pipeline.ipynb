{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69cdd325-c95b-44e1-b176-d3b712187e19",
   "metadata": {},
   "source": [
    "# Demo Detection: Обработка данных, обучение, демонстрация и экспорт модели\n",
    "\n",
    "Обучение модели было выполнено на M4 Pro MacBook Pro (24G RAM). Экспорт для\n",
    "Debian c RTX5060 (8G VRAM) на борту.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184b33a-708f-4854-814e-a9422161094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from preprocessing import TestTaskDatasetPreprocessor\n",
    "\n",
    "\n",
    "ROOT = \"../../\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a605c673-ccac-4003-a98e-973b9415a62e",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb48ca-da26-40c0-bb77-435e0c552b1a",
   "metadata": {},
   "source": [
    "## Обработка данных\n",
    "\n",
    "Исходные данные были представлены в виде директорий с кадрами из\n",
    "соответствующих чанков видео. Все кадры оказались упорядочены, поэтому\n",
    "построить соответствие между изображениями и аннотациями было нетрудно.\n",
    "Описанный ниже класс даёт абстракцию для перевода из исходного формата в\n",
    "подходящий для обучения YOLO26 от Ultralitycs.\n",
    "\n",
    "Конкретно с нашими путями его следует использовть следущим образом. Чтобы \n",
    "упростить задачу детекции для модели, не включаем в выборку класс трейлера.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c241ae-3ded-4605-b3fe-5f3849b1809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = ROOT + \"dataset/test_task_dl_26_12_2025/train/\"\n",
    "frames = [\n",
    "    \"2025-10-03_05_vt53_criterion_1_6_day_bw_panorama_1882x862\",\n",
    "    \"2025-10-03_05_vt53_criterion_1_8_day_bw_panorama_1882x862\",\n",
    "    \"2025-10-05T11-12_vt53_criterion_3_1_day_bw_panorama_1882x862\",\n",
    "]\n",
    "annotations = [\n",
    "    \"annotations_task_2299_2025-10-03_05_vt53_criterion_1_6_day_bw\"\n",
    "    + \"_panorama_1882x862.xml\",\n",
    "    \"annotations_task_2303_2025-10-03_05_vt53_criterion_1_8_day_bw\"\n",
    "    + \"_panorama_1882x862.xml\",\n",
    "    \"annotations_task_2310_2025-10-05T11-12_vt53_criterion_3_1_day_bw\"\n",
    "    + \"_panorama_1882x862.xml\",\n",
    "]\n",
    "\n",
    "paths_aligned = []\n",
    "for dir, file in zip(frames, annotations):\n",
    "    paths = (prefix + dir, prefix + file)\n",
    "    paths_aligned.append(paths)\n",
    "\n",
    "preprocessor = TestTaskDatasetPreprocessor(\n",
    "    root=ROOT + \"dataset/training_data_sample\",\n",
    "    class_map={\"car\": 0, \"truck\": 1},\n",
    "    image_dims=(1882.0, 862.0),\n",
    ")\n",
    "\n",
    "preprocessor.run(paths_aligned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d9c20a-5910-4372-9729-c7e8c5e81919",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4146bf-2961-43bb-af16-ce3a62078b10",
   "metadata": {},
   "source": [
    "## Обучение модели\n",
    "\n",
    "Обучаем модель 20 эпох (+-4 часа) с наиболее передовым оптимизатором. Размер\n",
    "пачки устанавливаем равным четырём (+-9.8G Unified Memory). По окончании\n",
    "процесса обучения файл модели будет находиться в пути\n",
    "ROOT/runs/detect/demo_detection/demo_detection_v4/best.pt. Однако промежуточные\n",
    "результаты храянтся в файле проекта (ROOT/runs/detect/demo_detection) с\n",
    "названием \"demo_detection_v4 + номер эпохи\".\n",
    "\n",
    "--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0327d-7879-4610-8b82-207dd04e2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(ROOT + \"models/yolo26m.pt\")\n",
    "\n",
    "model.train(\n",
    "    data=\"training_data.yaml\",\n",
    "    epochs=20,\n",
    "    imgsz=1280,\n",
    "    batch=4,\n",
    "    device=\"mps\",\n",
    "    amp=True,\n",
    "    cache=False,\n",
    "    workers=0,\n",
    "    rect=True,\n",
    "    optimizer=\"MuSGD\",\n",
    "    project=\"demo_detection\",\n",
    "    name=\"demo_detection_v4\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4451023d-1488-4067-ae7a-3d55d5b58ff8",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e05541-b745-4b3a-9310-db28d7aca057",
   "metadata": {},
   "source": [
    "## Детекция\n",
    "\n",
    "Прогон тестового видео через модель детекции осуществляется выполнением\n",
    "следующей строки в терминале:\n",
    "```\n",
    "python track.py\n",
    "```\n",
    "\n",
    "Подразумевается, что Вы уже находитесь в директории ROOT/src/python и уже\n",
    "активировали виртуальное окружение. Если это не так, скрипт может не найти путь\n",
    "к нужным файлам.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190f1017-7bfb-40eb-99e2-7e4e1e48fad9",
   "metadata": {},
   "source": [
    "## Экспорт модели\n",
    "\n",
    "Экпорт модели осуществляется в формате ONNX, чтобы обеспечить наибольшую\n",
    "совместимсоть со всеми видокартами NVIDIA GT1000+ серий и облегчить процесс\n",
    "реацлизации приложения на C++.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bbeb5f-b8d2-4b3f-9fa6-90ecef913a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(ROOT + \"models/demo_detection_v4e13.pt\")\n",
    "\n",
    "model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714ac687-1629-4b26-baf4-c34f4d03abb0",
   "metadata": {},
   "source": [
    "Проверим, что экспортированная модель запускается корректно.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b321132-de07-40bd-bfc3-592dfece7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = YOLO(ROOT + \"models/demo_detection_v4e13.onnx\")\n",
    "\n",
    "results = onnx_model(\n",
    "    ROOT + \"dataset/training_data/images/train/\"\n",
    "    + \"2025-10-03_05_vt53_criterion_1_6_day_bw_panorama_1882x862\"\n",
    "    + \"_video_20251004T061524_to_20251004T061535_11.0s_frame183.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01022503-3742-449b-84f8-c9be371bf5d4",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7836b730-8a64-49fa-bbba-f09b03a4d056",
   "metadata": {},
   "source": [
    "## Визуализация резульатов обучения и выводы\n",
    "\n",
    "С самого начала для решения задачи детекции была обучена YOLO26l, однако она\n",
    "не дала необходимого резульатат, так как, судя по всему, оказалась чересчур\n",
    "большой, а потому училась довольно медленно и 18-и эпох было недостаточно.\n",
    "\n",
    "Позже было решено заменить её на YOLO26m, потому что она более портативна, с\n",
    "большей вероятностью даст треубемую прозиводительность на GPU с архитектурой\n",
    "Pascal (GT1000 серии) и быстрее обучится, потребляя при этом меньшее количество\n",
    "энергии.\n",
    "\n",
    "На графике ниже можно увидеть сопоставление процессов обучения двух моделей.\n",
    "Любопытно, что метрики, на самом деле, не так далеки друг от друга, но YOLO26m\n",
    "в итоге лучше справилась с детекцией грузовика, не спутав его при этом с ТС\n",
    "легкового типа.\n",
    "\n",
    "Видео и статистики находятся в директории ROOT/models/training_results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23744d-3a17-4af6-beb4-4a5ca98c1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_logs(file_path, model_label):\n",
    "    df = pl.read_csv(file_path)\n",
    "\n",
    "    return df.with_columns(\n",
    "        [\n",
    "            pl.lit(model_label).alias(\"model\"),\n",
    "            (\n",
    "                (pl.col(\"time\").diff().fill_null(pl.col(\"time\").first())) / 60\n",
    "            ).alias(\"epoch_time\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "df_l = process_logs(\n",
    "    ROOT + \"models/training_results/demo_detection_v3e18.csv\", \"YOLO26l\"\n",
    ")\n",
    "df_m = process_logs(\n",
    "    ROOT + \"models/training_results/demo_detection_v4e13.csv\", \"YOLO26m\"\n",
    ")\n",
    "\n",
    "df_combined = pl.concat([df_l, df_m])\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle(\n",
    "    \"Сравнение моделей: YOLO26l vs YOLO26m\\n(Детекция легковых и грузовых автомобилей)\",\n",
    "    fontsize=20,\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_combined,\n",
    "    x=\"epoch\",\n",
    "    y=\"metrics/mAP50(B)\",\n",
    "    hue=\"model\",\n",
    "    ax=axes[0, 0],\n",
    "    marker=\"o\",\n",
    "    linewidth=2.5,\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=df_combined,\n",
    "    x=\"epoch\",\n",
    "    y=\"metrics/mAP50-95(B)\",\n",
    "    hue=\"model\",\n",
    "    ax=axes[0, 0],\n",
    "    marker=\"s\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "axes[0, 0].set_title(\n",
    "    \"Точность детекции: mAP@.5 (сплошная) и mAP@.5:.95 (пунктир)\", fontsize=14\n",
    ")\n",
    "axes[0, 0].set_ylabel(\"Значение mAP\")\n",
    "axes[0, 0].set_xlabel(\"Эпоха\")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_combined,\n",
    "    x=\"epoch\",\n",
    "    y=\"val/box_loss\",\n",
    "    hue=\"model\",\n",
    "    ax=axes[0, 1],\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    ")\n",
    "axes[0, 1].set_title(\n",
    "    \"Стабильность регрессии рамок (Box Loss на валидации)\", fontsize=14\n",
    ")\n",
    "axes[0, 1].set_ylabel(\"Функция потерь (Loss)\")\n",
    "axes[0, 1].set_xlabel(\"Эпоха\")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_combined,\n",
    "    x=\"epoch\",\n",
    "    y=\"metrics/precision(B)\",\n",
    "    hue=\"model\",\n",
    "    ax=axes[1, 0],\n",
    "    marker=\"o\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=df_combined,\n",
    "    x=\"epoch\",\n",
    "    y=\"metrics/recall(B)\",\n",
    "    hue=\"model\",\n",
    "    ax=axes[1, 0],\n",
    "    marker=\"x\",\n",
    "    linestyle=\":\",\n",
    ")\n",
    "axes[1, 0].set_title(\"Точность (сплошная) vs. Полнота (пунктир)\", fontsize=14)\n",
    "axes[1, 0].set_ylabel(\"Метрика (0-1)\")\n",
    "axes[1, 0].set_xlabel(\"Эпоха\")\n",
    "\n",
    "sns.barplot(\n",
    "    data=df_combined, x=\"epoch\", y=\"epoch_time\", hue=\"model\", ax=axes[1, 1]\n",
    ")\n",
    "axes[1, 1].set_title(\"Затраты времени на эпоху (в минутах)\", fontsize=14)\n",
    "axes[1, 1].set_ylabel(\"Длительность (мин)\")\n",
    "axes[1, 1].set_xlabel(\"Эпоха\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n",
    "plt.savefig(\n",
    "    ROOT + \"models/training_results/demo_detection_comparison_dashboard.png\",\n",
    "    dpi=300,\n",
    ")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
